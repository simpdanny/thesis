\section{研究動機與背景}

長久以來，科技的發展早已走向花花綠綠，聲色斑駁的世代。絢爛的圖片影像、繁複錯落的聲音樂曲，連結人們日常生活的已經不再是書本上的文字，而是各種多媒體層層交疊的網路生活。其中，語音辨識應運而生，人們一邊訝異機器能夠把人的聲音訊號打成文字，一邊又享受機器聽懂人話後的各種方便福利。從最基本的的行動裝置語音輸入，後來的語音檢索，甚至發展成語音助理如Google Now, Microsoft Cortana及Apple Siri，都深深刻刻地使用了語音辨識及相關的語音處理技術。

隨著網路與相關科技的成長，語音辨識彷彿逆著馬斯洛的人類需求金字塔一般。一開始，人們追求語音辨識只不過是一種自我實現，展現科技的威能：而現在，語音辨識已經貼近人們的需求，居家照顧、生活機能等等廣泛的應用，使得人類越來越無法脫離這個方便迅速的「口說」世代。而這樣的發展顯然是全球化的，地球上無論是說著德文、西班牙文、英文還是中文的人，都無法抵抗這迅速發展的洪流，只能擁抱日益新穎的科技，融入日常。

語言的高度變化，一直以來都是語音辨識系統最大的挑戰。不同語系、不同腔調、非母語者甚至是不同使用者講的同一個語言，都不見得適用同一個系統。直觀而言，我們可以為每一個語言，建立一個獨自的語音辨識系統，然世界上語言何其多，語言之間也不必然完全獨立，各自為政不免冗贅。如何運用語言之間的共通特性，重複利用，進而適應各種可能的語音環境，是語音辨識中的核心課題。
\section{相關研究}
以往的語音辨識，都習慣將聲音拆解成不同層級的發單位，如語言學上的音素（Phoneme）、或是模擬發音連續狀態的三連音態（Tri-state, or senone）。當聲學模型（Acoustic Model）建立後，即與語言模型（Language Model）結合成辨識系統。
 
自從辛氏（Hinto）將深層類神經網路（Deep Neural Network, DNN）套用到聲學模型後，語音辨識系統的辨識率突飛猛進，研究者紛紛踏入深度學習的領域，試圖找尋更潛在的隱藏層（Hidden Layer）資訊。更有研究者直接跳脫語言學的知識，回歸問題的本質，建立了端至端（End-to-End）語音辨識系統，不再有音素或是發音狀態的概念，移除了語言學對於深度學習的框架限制。隨著網路頻寬的擴增的與大資料背景的加持，以往仰賴資料量的深度學習不再成為瓶頸，這些方法紛紛獲得顯著的成功。

深度學習的架構非常多元，大多是以類神經網路為基礎延伸而成。有能夠抓取圖像中空間頻率的卷積類神經網路（Convolutional Neural Network, CNN）、能夠抓取短期時間資訊的遞迴式類神經網路（Recurrent Neural Network, RNN）、利用閘道存取長時間時間資訊的長短期記憶神經網路（Long Short-term Memory, LSTM）等等。

儘管有這麼豐富的方法，多語言語音辨識系統中仍然有許多難以克服的情景。如原生語音辨識系統與非母語（Nonnative）或是不同地區腔調（Accented）使用者的不匹配問題（Mismatch）、雙語混和（Code-mixing）使用者的語言切換問題（Code-switching）。少數語言的資源過少問題（Low-resource）。這些問題，追根究底都是因為實際雲端資料庫中儲存的資料量不足，使得系統無法完善。常見的解決方法如發音單位合併（Pronunication Unit Merging）、多目標學習（Multitask Learning）、聲學模型共享（Acoustic Model Sharing）、跨語言轉移學習（Crosslingual Transfer Learning）、半監督式學習（Semi-supervised Learning），也都是從資料量的角度切入，擴增可用的資料，讓深度學習的結果變得更可靠。

為了避免深度學習過度適應（Overfitting）於少量的訓練資料，機器學習的研究者發展出控制調適（Regularization），像是隨機調適的丟棄演算法（Dropout）、模型簡單化的二階參數衰減法（L2 Weight Decay）、或是知識蒸餾演算法（Knowledge Distillation）。藉由控制調適，能夠提高深度學習模型的概括化能力（Generaliaztion），從而學習到少數資料量以外的更多可能。強力的控制子（Regularizer）甚至可以簡化模型的架構，讓小型的行動裝置亦能配備，增加應用可以運用的空間範圍。

\section{研究方向}
本論文之研究方向在探討以深度學習建立的多語言語音辨識系統聲學模型，主要包含以下幾點：

\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  第一階段先探討多個語言間如何合作分享資訊，以用較少的資料獲得更好的辨識結果。

  \item  第二階段則探討如何利用知識蒸餾幫助多語言的深層類神經網路學習，提昇模型的概括化能力。

\end{itemize}
\section{章節安排}
本論文各章節簡述如下：
\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  第二章：介紹深度學習的深層類神經網路架構與基本訓練方法，以及本論文研究所使用的語料全球音素資料庫（GlobalPhone Corpus）還有常見的多語言語音辨識系統情景。

  \item  第三章：建立四個語言：德文（German, GE）、西班牙文（Spanish, SP）、捷克文（Czech, CZ）、法文（French, FR）的單語言（Monolingual）語音辨識系統，以便之後的比較。為了讓深度學習的結果更適合討論與擴展而不受限於語言知識，因此筆者特別挑了四個完全不熟悉的語言。

  \item  第四章：建立四個語言的多語言（Multilingual）語音辨識系統，從最粗糙的音素到最細緻的隱藏層，合併三個不同層級的發音單位，並討論不同層級合併的意義與結果。

  \item  第五章：介紹如何以知識蒸餾來控制調適深度學習模型，並且設計實驗套用於多語言語音辨識系統上，進而討論模型壓縮與概括化的能力。
   
  \item  第六章：總結本論文的研究成果與研究精神，並討論未來的研究方向。
\end{itemize}

