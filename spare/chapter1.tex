\section{研究動機}
現在是一個資訊爆炸的時代，每天資訊的增長量是十分驚人的，因此，我們需要一套好的檢索系統 (Retrieval System) 幫助我們快速地瀏覽資訊，並找到其中有用的部分，在過去已有許多文字檢索系統與演算法被開發出來並應用於產業中，如 Google Search、Microsoft Bing Search、Yahoo
Search等。但近年來隨著科技與網際網路的興起，語音文件量正蓬勃地增加當中，隨著線上影片、會議錄音、線上課程等網站的興起，語音資料量越來越多，因此如何在其中找到使用者感興趣的資料便成為重要的議題，即為語音數位內容檢索 (Spoken Content Retrieval)~\cite{chelba2008retrieval, lee2005spoken}。相較於文字資訊檢索，語音資訊檢索面臨到更多的挑戰，如辨識錯誤、辨識訓練資料不足等問題，使得此問題更形困難。

近年來更由於智慧型手機的崛起與使用者需要在移動裝置上取得資訊的強烈需求，促使許多網路公司一一推出了自家的用語音輸入來檢索文字資訊的系統，如 Google 公司推出的語音檢索功能即可讓使用者在手機或瀏覽器的介面上以語音輸入，由 Google 將其辨識成文字後再於 Google 的搜尋引擎上檢索資訊。 Apple 公司推出的個人語音助理 Siri，也讓使用者能以十分自然的方式對 Siri 說出想要查詢的查詢詞 (Query) ，由 Siri 辨識後在網路上檢索，並將檢索結果分門別類整理好後呈現給使用者看。如上述所說的這類檢索系統是用語音輸入的查詢詞去檢索大量的文字資訊，此方法稱為人聲檢索 (Voice Search)，和本論文所探討的語音數位內容檢索 (Spoken Content Retrieval) 完全不同。

本論文所探討的語音數位內容檢索，是指由於網路上有大量的多媒體文件，如線上影片、會議錄音、線上課程、電視連續劇、演講等，而使用者也有搜尋這些多媒體文件的需求，此類允許使用者用文字或聲音輸入查詢詞並搜尋語音數位內容 (Spoken Content) 的系統稱為語音數位內容檢索 (Spoken Content Retrieval)，如 TED (美國著名的演講網站) 會將網站上的演講內容轉寫 (Transcript) 成為文字，並允許使用者於網站上輸入文字檢索這些影片的文字稿。 Youtube 也會於離線時將其網站上的影片辨識成文字，但目前尚不支援直接輸入查詢詞檢索影片轉寫的方式，可以期待未來 Youtube 會開放這方面的功能。只是上述兩個例子仍要倚賴人工的轉寫，要完全只靠機器自動辨識仍不容易做到。這種語音數位內容檢索將是本論文主要的研究主軸。

由於以上所述的語音數位內容檢索系統大部分都是回傳給使用者有出現查詢詞的語音文件，但如此一來使用者必須完美地輸入有出現在語音文件中的查詢詞，如果使用者心中想的概念與語音文件中的詞彙不匹配，則檢索系統的成效就會大大地降低。使用者通常期待的是系統會查到所有與查詢詞「語意上相關」的文件，比如查詢詞為「東京旅遊」的話，使用者想要查詢到的文件通常包含與「東京住宿」、「東京景點」等有關的結果，而不只是那些包含了「東京旅遊」的文件。此即為語意檢索 (Semantic Retrieval) 的系統。語意檢索一個很常見的實作方法是查詢詞擴展 (Query
Expansion)，查詢詞擴展的精神是先進行第一次檢索，得到第一次檢索結果 (First-pass Retrieval Result)，並從其中最相關的前幾篇中找出常常出現卻不是在所有文章中都常常出現的詞，再加入到原查詢詞中成為擴展後查詢詞 (Expanded Query)，再使用擴展後查詢詞進行第二次檢索 (Second-pass Retrieval)。

本論文想要探討的主題將是針對語音數位內容之語意檢索 (Semantic Retrieval of Spoken Content)，是指系統在接受到口語形式或文字形式的查詢詞之後，儘可能回傳給使用者所有與查詢詞語意上相關的語音文件。由於傳統的語音數位內容之語意檢索系統主要的實作方法為先將語音文件辨識為文字檔後，對文字做檢索，但在辨識之中，會遇到如詞典外詞彙
(OOV)、辨識錯誤等情況，更甚者，許多語音中珍貴的資訊如韻律 (Prosody)、語速 (Speaking Rate)和語者特徵 (Speaker Characteristic)等在辨識後就消失了，十分地可惜。因此本論文試圖結合一套自動習得的聲學組型 (Automatically Discovered Acoustic Patterns) 至語音數位內容之語意檢索當中，以期改善傳統的檢索系統。

\section{研究方向}
本論文之研究方向為使用自動習得之聲學組型強化語音數位內容之語意檢索，主要包含以下幾點：

\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  傳統的語意檢索系統是先將語音文件辨識為文字後，將輸入的文字查詢詞進行查詢詞擴展 (Query Expansion)，再用擴展後查詢詞對辨識後的文字進行檢索，但如此一來許多語音訊號中的珍貴的聲學資訊就消失了。因此本章中在文字的查詢詞擴展之外，再加入一套自動習得之聲學組型的查詢詞擴展，並結合兩套查詢詞擴展之結果回傳給使用者。

  \item  更進一步地，本論文希望能處理口語形式的查詢詞，可以用口語形式的查詢詞進行語音數位內容之語意檢索。另一方面，語意檢索通常需要自動語音辨識系統 (Automatically Speech Recognition) 將聲音辨識成文字，進而得到語意上的資訊，但自動語音辨識系統的訓練是很昂貴的，需要大量標注完善的語料才能訓練出很好的聲學與語言模型。因此本章中會將聲音辨識成聲學組型，並在聲學組型上進行查詢詞擴展，進而達到非監督式語音數位內容之語意檢索 (Unsupervised Semantic Retrieval of Spoken Content)。
  
  \item  由於聲學組型在訓練時是盡量將聲音很像之片段盡量分群 (Clustering) 在一起，但如此一來會使得同一個聲學組型中包含了大量同音但對應到不同字詞的聲學組型，會使得檢索系統的成效大幅下降。因此本章使用基於遞迴式類神經網路語言模型 (Recurrent Neural Network Language Model, RNNLM) 之詞表示法 (Word Representation) 將這些聲學組型按照句法 (Syntactics) 和語意 (Semantics) 進一步分群為不同的聲學組型，進而提升檢索系統之成效。
   
  \item  最後，由於近年來行動裝置與穿戴式裝置日漸流行，使用者也漸漸習慣於在行動裝置上用語音輸入並取得資訊，因此本論文基於 Google 眼鏡 ( Google Glass) 上推出了一套語音翻譯系統與語音數位內容檢索系統，讓使用者能夠隨時隨地用最方便的方法取得新資訊。

\end{itemize}

\section{章節安排}
本論文之章節安排如下：

\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  第二章：介紹本論文相關背景知識。
  \item  第三章：介紹如何以聲學組型改善監督式語意檢索。
  \item  第四章：介紹如何以聲學組型實現非監督式語意檢索。
  \item  第五章：介紹如何以遞迴式類神經網路語言模型產生之詞向量改善第四章的非監督式語音文件檢索。
  \item  第六章：介紹如何將本論文之語音檢索系統與語音翻譯系統實作到 Google Glass 上。
  \item  第七章：本論文之結論與未來研究方向。
\end{itemize}

